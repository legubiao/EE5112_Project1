{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2dfcac-3e77-4386-a09f-a6ca8f77350c",
   "metadata": {},
   "source": [
    "# Task 2: Understand body language by gesture recognition with convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b2526-0909-476e-82ca-f688785da04d",
   "metadata": {},
   "source": [
    "## 1. Do literature search on Convolution Neural Network. Learn how to build a convolutional layer in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc76db6-4a78-42d2-b6e7-8835a48df88c",
   "metadata": {},
   "source": [
    "## 2. Referring to the guide in Task 1, build your own network for gesture classification using convolutional layers. Please see the references 4 in the manual to learn how to build convolutional layers in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b39684-c416-4dcc-b380-27d86876dbea",
   "metadata": {},
   "source": [
    "## 3. Analyse and comment on the performance of the model. Make a comparison between the fully connected based and convolutional based models and comment on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9773f3b5-7c51-43dc-8e2b-2b312f1501a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import torch.utils.data as utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7aa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSkinImage(filePath, resize_HW=48):\n",
    "    # step 1\n",
    "    # read the image\n",
    "    original = cv2.imread(filename=filePath)\n",
    "\n",
    "    # step 2\n",
    "    # resize the image to\n",
    "    image_resized = cv2.resize(original, (resize_HW, resize_HW))\n",
    "\n",
    "    # step 3\n",
    "    # convert the image from rgb to YCbCr\n",
    "    image_ycbcr = cv2.cvtColor(image_resized, cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    # step 4\n",
    "    # get the central color of the image\n",
    "    # expected the hand to be in the central of the image\n",
    "    Cb_center_color = image_ycbcr[int(resize_HW/2), int(resize_HW/2), 1]\n",
    "    Cr_center_color = image_ycbcr[int(resize_HW/2), int(resize_HW/2), 2]\n",
    "    # set the range\n",
    "    Cb_Difference = 15\n",
    "    Cr_Difference = 10\n",
    "\n",
    "    # step 5\n",
    "    # detect skin pixels\n",
    "    Cb = image_ycbcr[:, :, 1]\n",
    "    Cr = image_ycbcr[:, :, 2]\n",
    "    index = np.where((Cb >= Cb_center_color-Cb_Difference) & (Cb <= Cb_center_color+Cb_Difference)\n",
    "                     & (Cr >= Cr_center_color-Cr_Difference) & (Cr <= Cr_center_color+Cr_Difference))\n",
    "\n",
    "    # Mark detected pixels and output\n",
    "    image_output = np.zeros((resize_HW, resize_HW))\n",
    "    image_output[index] = 255\n",
    "\n",
    "    # show image\n",
    "    # cv2.imshow(\"\", image_output)\n",
    "    # cv2.waitKey(0)\n",
    "    return image_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff65e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/images'\n",
    "path_processed = './dataset_processed/images'\n",
    "\n",
    "# -------------------images processing--------------\n",
    "for mainDir, subDir, fileList in os.walk(path):\n",
    "    for file in fileList:\n",
    "        currentPath = os.path.join(mainDir, file)\n",
    "        # print(\"Processing file:\", currentPath)\n",
    "        processedImage = processSkinImage(currentPath)\n",
    "\n",
    "        new_mainDir = path_processed + mainDir.split(path)[-1]\n",
    "        if not os.path.exists(new_mainDir):\n",
    "            os.makedirs(new_mainDir)\n",
    "        cv2.imwrite(os.path.join(new_mainDir, file), processedImage)\n",
    "\n",
    "# -----------------label generation----------------\n",
    "label_path = './dataset_processed/labels'\n",
    "if not os.path.exists(label_path):\n",
    "    os.makedirs(label_path)\n",
    "\n",
    "files = os.listdir(path)\n",
    "for i, file in enumerate(files):\n",
    "    subclass_label_path = os.path.join(label_path, file+'.txt')\n",
    "    with open(subclass_label_path, 'w') as f:\n",
    "        f.write('#label\\n')\n",
    "    for _ in range(len(os.listdir(os.path.join(path_processed, file)))):\n",
    "        with open(subclass_label_path, 'a') as f:\n",
    "            f.write('{:d}\\n'.format(i))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba78f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = []\n",
    "path_images = './dataset_processed/images'\n",
    "for mainDir, subDir, fileList in os.walk(path_images):\n",
    "    for file in fileList:\n",
    "        currentPath = os.path.join(mainDir, file)\n",
    "        Image.append(cv2.imread(currentPath)[:, :, 0])\n",
    "Image = np.array(Image)\n",
    "dataset_size, H, W = Image.shape\n",
    "# # for FCNN model, the image need to be stretched into one dimension: (b, h, w)->(b, h*w)\n",
    "# Image = Image.reshape(dataset_size, -1)\n",
    "\n",
    "\n",
    "Label = []\n",
    "path_labels = './dataset_processed/labels'\n",
    "for file in os.listdir(path_labels):\n",
    "    Label.append(np.loadtxt(os.path.join(path_labels, file)))\n",
    "Label = np.array(list(itertools.chain.from_iterable(Label)))\n",
    "num_classes = int(np.max(Label))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b980a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils_data\n",
    "class ConvModule(torch.nn.Module):\n",
    "    def __init__(self,input_channel=1):\n",
    "        super(ConvModule, self).__init__()\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            # (batch_size, input_channel, H, W)->(batch_size, 32, H-2, W-2)\n",
    "            torch.nn.Conv2d(in_channels=input_channel, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            # (batch_size, 32, H-2, W-2)->(batch_size, 64, H-4, W-4)\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            # (batch_size, 64, H-4, W-4)->(batch_size, 128, H-6, W-6)\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        #(128)->(4)\n",
    "        self.fc = torch.nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        X=X.unsqueeze(1)\n",
    "        # X = X.to(device)\n",
    "        out = self.conv(X)  # (batch_size, 128, H - 6, W - 6)\n",
    "        # 48-2-2-2=42\n",
    "        out = F.avg_pool2d(out, 42)  # (batch_size, 128, 1, 1)\n",
    "        # (batch_size, 128, 1, 1)->(batch_size, 128)\n",
    "        out = out.squeeze()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7dad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvModule()\n",
    "model.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8341546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "dataset = utils_data.TensorDataset(torch.Tensor(Image), torch.LongTensor(Label))\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_set, test_set = utils_data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = utils_data.DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
    "test_loader = utils_data.DataLoader(dataset=test_set, batch_size=8, shuffle=True)\n",
    "print('Data is ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb7d4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\ttrain loss=1.317035\ttrain accuracy=0.435\ttest accuracy=0.312\n",
      "epoch=1\ttrain loss=1.144255\ttrain accuracy=0.597\ttest accuracy=0.438\n",
      "epoch=2\ttrain loss=1.042952\ttrain accuracy=0.645\ttest accuracy=0.562\n",
      "epoch=3\ttrain loss=0.965909\ttrain accuracy=0.694\ttest accuracy=0.562\n",
      "epoch=4\ttrain loss=0.868321\ttrain accuracy=0.758\ttest accuracy=0.562\n",
      "epoch=5\ttrain loss=0.830863\ttrain accuracy=0.742\ttest accuracy=0.562\n",
      "epoch=6\ttrain loss=0.806307\ttrain accuracy=0.774\ttest accuracy=0.562\n",
      "epoch=7\ttrain loss=0.764963\ttrain accuracy=0.758\ttest accuracy=0.562\n",
      "epoch=8\ttrain loss=0.796097\ttrain accuracy=0.742\ttest accuracy=0.562\n",
      "epoch=9\ttrain loss=0.742847\ttrain accuracy=0.774\ttest accuracy=0.750\n",
      "epoch=10\ttrain loss=0.667815\ttrain accuracy=0.839\ttest accuracy=0.812\n",
      "epoch=11\ttrain loss=0.609922\ttrain accuracy=0.839\ttest accuracy=0.625\n",
      "epoch=12\ttrain loss=0.614720\ttrain accuracy=0.790\ttest accuracy=0.562\n",
      "epoch=13\ttrain loss=0.592397\ttrain accuracy=0.806\ttest accuracy=0.812\n",
      "epoch=14\ttrain loss=0.634619\ttrain accuracy=0.823\ttest accuracy=0.688\n",
      "epoch=15\ttrain loss=0.628981\ttrain accuracy=0.806\ttest accuracy=0.625\n",
      "epoch=16\ttrain loss=0.534727\ttrain accuracy=0.806\ttest accuracy=0.688\n",
      "epoch=17\ttrain loss=0.538145\ttrain accuracy=0.823\ttest accuracy=0.938\n",
      "epoch=18\ttrain loss=0.528747\ttrain accuracy=0.855\ttest accuracy=0.750\n",
      "epoch=19\ttrain loss=0.563809\ttrain accuracy=0.855\ttest accuracy=0.875\n",
      "epoch=20\ttrain loss=0.480997\ttrain accuracy=0.919\ttest accuracy=0.875\n",
      "epoch=21\ttrain loss=0.441502\ttrain accuracy=0.871\ttest accuracy=0.750\n",
      "epoch=22\ttrain loss=0.517309\ttrain accuracy=0.790\ttest accuracy=0.750\n",
      "epoch=23\ttrain loss=0.480754\ttrain accuracy=0.839\ttest accuracy=0.875\n",
      "epoch=24\ttrain loss=0.463357\ttrain accuracy=0.919\ttest accuracy=0.938\n",
      "epoch=25\ttrain loss=0.422659\ttrain accuracy=0.919\ttest accuracy=0.938\n",
      "epoch=26\ttrain loss=0.395294\ttrain accuracy=0.919\ttest accuracy=0.938\n",
      "epoch=27\ttrain loss=0.391941\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=28\ttrain loss=0.400557\ttrain accuracy=0.887\ttest accuracy=0.938\n",
      "epoch=29\ttrain loss=0.436304\ttrain accuracy=0.903\ttest accuracy=0.875\n",
      "epoch=30\ttrain loss=0.396893\ttrain accuracy=0.935\ttest accuracy=0.750\n",
      "epoch=31\ttrain loss=0.424639\ttrain accuracy=0.855\ttest accuracy=1.000\n",
      "epoch=32\ttrain loss=0.383967\ttrain accuracy=0.935\ttest accuracy=0.875\n",
      "epoch=33\ttrain loss=0.371239\ttrain accuracy=0.935\ttest accuracy=0.875\n",
      "epoch=34\ttrain loss=0.429028\ttrain accuracy=0.903\ttest accuracy=0.938\n",
      "epoch=35\ttrain loss=0.468784\ttrain accuracy=0.823\ttest accuracy=0.875\n",
      "epoch=36\ttrain loss=0.361293\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=37\ttrain loss=0.375998\ttrain accuracy=0.887\ttest accuracy=0.875\n",
      "epoch=38\ttrain loss=0.399734\ttrain accuracy=0.952\ttest accuracy=0.875\n",
      "epoch=39\ttrain loss=0.385043\ttrain accuracy=0.919\ttest accuracy=0.938\n",
      "epoch=40\ttrain loss=0.365660\ttrain accuracy=0.935\ttest accuracy=0.938\n",
      "epoch=41\ttrain loss=0.294061\ttrain accuracy=0.952\ttest accuracy=0.938\n",
      "epoch=42\ttrain loss=0.341176\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=43\ttrain loss=0.257259\ttrain accuracy=0.952\ttest accuracy=0.938\n",
      "epoch=44\ttrain loss=0.284841\ttrain accuracy=0.952\ttest accuracy=0.875\n",
      "epoch=45\ttrain loss=0.258956\ttrain accuracy=0.968\ttest accuracy=0.938\n",
      "epoch=46\ttrain loss=0.283109\ttrain accuracy=0.952\ttest accuracy=1.000\n",
      "epoch=47\ttrain loss=0.254157\ttrain accuracy=0.952\ttest accuracy=1.000\n",
      "epoch=48\ttrain loss=0.310927\ttrain accuracy=0.952\ttest accuracy=1.000\n",
      "epoch=49\ttrain loss=0.236726\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=50\ttrain loss=0.290520\ttrain accuracy=0.952\ttest accuracy=0.938\n",
      "epoch=51\ttrain loss=0.258100\ttrain accuracy=0.935\ttest accuracy=0.938\n",
      "epoch=52\ttrain loss=0.259541\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=53\ttrain loss=0.256044\ttrain accuracy=0.952\ttest accuracy=0.812\n",
      "epoch=54\ttrain loss=0.233768\ttrain accuracy=0.984\ttest accuracy=0.562\n",
      "epoch=55\ttrain loss=0.326283\ttrain accuracy=0.919\ttest accuracy=0.875\n",
      "epoch=56\ttrain loss=0.251011\ttrain accuracy=0.952\ttest accuracy=0.875\n",
      "epoch=57\ttrain loss=0.215459\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=58\ttrain loss=0.231191\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=59\ttrain loss=0.218188\ttrain accuracy=0.952\ttest accuracy=0.875\n",
      "epoch=60\ttrain loss=0.235544\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=61\ttrain loss=0.211929\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=62\ttrain loss=0.172229\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=63\ttrain loss=0.222003\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=64\ttrain loss=0.194321\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=65\ttrain loss=0.188538\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=66\ttrain loss=0.204097\ttrain accuracy=0.952\ttest accuracy=0.938\n",
      "epoch=67\ttrain loss=0.235200\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=68\ttrain loss=0.161605\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=69\ttrain loss=0.228392\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=70\ttrain loss=0.182929\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=71\ttrain loss=0.197545\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=72\ttrain loss=0.152923\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=73\ttrain loss=0.207805\ttrain accuracy=0.952\ttest accuracy=0.938\n",
      "epoch=74\ttrain loss=0.183423\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=75\ttrain loss=0.304035\ttrain accuracy=0.919\ttest accuracy=0.688\n",
      "epoch=76\ttrain loss=0.254779\ttrain accuracy=0.968\ttest accuracy=0.625\n",
      "epoch=77\ttrain loss=0.204631\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=78\ttrain loss=0.315523\ttrain accuracy=0.887\ttest accuracy=0.938\n",
      "epoch=79\ttrain loss=0.221334\ttrain accuracy=0.968\ttest accuracy=0.938\n",
      "epoch=80\ttrain loss=0.213191\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=81\ttrain loss=0.193035\ttrain accuracy=0.968\ttest accuracy=0.938\n",
      "epoch=82\ttrain loss=0.114551\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=83\ttrain loss=0.147413\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=84\ttrain loss=0.167044\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=85\ttrain loss=0.107473\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=86\ttrain loss=0.149038\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=87\ttrain loss=0.142364\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=88\ttrain loss=0.177779\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=89\ttrain loss=0.162563\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=90\ttrain loss=0.196575\ttrain accuracy=0.952\ttest accuracy=0.938\n",
      "epoch=91\ttrain loss=0.163074\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=92\ttrain loss=0.177630\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=93\ttrain loss=0.129556\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=94\ttrain loss=0.102590\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=95\ttrain loss=0.137117\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=96\ttrain loss=0.256816\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=97\ttrain loss=0.138102\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=98\ttrain loss=0.197359\ttrain accuracy=0.968\ttest accuracy=0.812\n",
      "epoch=99\ttrain loss=0.174337\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=100\ttrain loss=0.147919\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=101\ttrain loss=0.154621\ttrain accuracy=0.968\ttest accuracy=0.812\n",
      "epoch=102\ttrain loss=0.111178\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=103\ttrain loss=0.102398\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=104\ttrain loss=0.119275\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=105\ttrain loss=0.113806\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=106\ttrain loss=0.130073\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=107\ttrain loss=0.119230\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=108\ttrain loss=0.105620\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=109\ttrain loss=0.128304\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=110\ttrain loss=0.117832\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=111\ttrain loss=0.109391\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=112\ttrain loss=0.101807\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=113\ttrain loss=0.086206\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=114\ttrain loss=0.105440\ttrain accuracy=1.000\ttest accuracy=0.750\n",
      "epoch=115\ttrain loss=0.131789\ttrain accuracy=0.968\ttest accuracy=0.812\n",
      "epoch=116\ttrain loss=0.155695\ttrain accuracy=0.968\ttest accuracy=0.875\n",
      "epoch=117\ttrain loss=0.130154\ttrain accuracy=0.984\ttest accuracy=0.938\n",
      "epoch=118\ttrain loss=0.117120\ttrain accuracy=0.984\ttest accuracy=0.500\n",
      "epoch=119\ttrain loss=0.152227\ttrain accuracy=0.952\ttest accuracy=0.875\n",
      "epoch=120\ttrain loss=0.082104\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=121\ttrain loss=0.088250\ttrain accuracy=0.968\ttest accuracy=0.938\n",
      "epoch=122\ttrain loss=0.103386\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=123\ttrain loss=0.073618\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=124\ttrain loss=0.079823\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=125\ttrain loss=0.086957\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=126\ttrain loss=0.069999\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=127\ttrain loss=0.100541\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=128\ttrain loss=0.049804\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=129\ttrain loss=0.065221\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=130\ttrain loss=0.062223\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=131\ttrain loss=0.063625\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=132\ttrain loss=0.119063\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=133\ttrain loss=0.200341\ttrain accuracy=0.935\ttest accuracy=1.000\n",
      "epoch=134\ttrain loss=0.102018\ttrain accuracy=0.984\ttest accuracy=0.250\n",
      "epoch=135\ttrain loss=0.140945\ttrain accuracy=0.968\ttest accuracy=0.938\n",
      "epoch=136\ttrain loss=0.088027\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=137\ttrain loss=0.075293\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=138\ttrain loss=0.056626\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=139\ttrain loss=0.073671\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=140\ttrain loss=0.104583\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=141\ttrain loss=0.078175\ttrain accuracy=0.984\ttest accuracy=1.000\n",
      "epoch=142\ttrain loss=0.071771\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=143\ttrain loss=0.051897\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=144\ttrain loss=0.047769\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=145\ttrain loss=0.039225\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=146\ttrain loss=0.038156\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=147\ttrain loss=0.035602\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=148\ttrain loss=0.040262\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=149\ttrain loss=0.072032\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=150\ttrain loss=0.058218\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=151\ttrain loss=0.055131\ttrain accuracy=1.000\ttest accuracy=0.750\n",
      "epoch=152\ttrain loss=0.047544\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=153\ttrain loss=0.046915\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=154\ttrain loss=0.039601\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=155\ttrain loss=0.046706\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=156\ttrain loss=0.050125\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=157\ttrain loss=0.044812\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=158\ttrain loss=0.044156\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=159\ttrain loss=0.031906\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=160\ttrain loss=0.041010\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=161\ttrain loss=0.031435\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=162\ttrain loss=0.031158\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=163\ttrain loss=0.037340\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=164\ttrain loss=0.044864\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=165\ttrain loss=0.066277\ttrain accuracy=0.984\ttest accuracy=0.562\n",
      "epoch=166\ttrain loss=0.054504\ttrain accuracy=1.000\ttest accuracy=0.688\n",
      "epoch=167\ttrain loss=0.083643\ttrain accuracy=0.984\ttest accuracy=0.750\n",
      "epoch=168\ttrain loss=0.097867\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=169\ttrain loss=0.080277\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=170\ttrain loss=0.047102\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=171\ttrain loss=0.044439\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=172\ttrain loss=0.052081\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=173\ttrain loss=0.038816\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=174\ttrain loss=0.046777\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=175\ttrain loss=0.038511\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=176\ttrain loss=0.023524\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=177\ttrain loss=0.051902\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=178\ttrain loss=0.022793\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=179\ttrain loss=0.024896\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=180\ttrain loss=0.042817\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=181\ttrain loss=0.043112\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=182\ttrain loss=0.034929\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=183\ttrain loss=0.036342\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=184\ttrain loss=0.027962\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=185\ttrain loss=0.035970\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=186\ttrain loss=0.036922\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=187\ttrain loss=0.032090\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=188\ttrain loss=0.047856\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=189\ttrain loss=0.028308\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=190\ttrain loss=0.041655\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=191\ttrain loss=0.076623\ttrain accuracy=0.984\ttest accuracy=0.812\n",
      "epoch=192\ttrain loss=0.162051\ttrain accuracy=0.935\ttest accuracy=0.938\n",
      "epoch=193\ttrain loss=0.113526\ttrain accuracy=0.968\ttest accuracy=0.625\n",
      "epoch=194\ttrain loss=0.089185\ttrain accuracy=0.984\ttest accuracy=0.562\n",
      "epoch=195\ttrain loss=0.052498\ttrain accuracy=1.000\ttest accuracy=0.875\n",
      "epoch=196\ttrain loss=0.066236\ttrain accuracy=0.984\ttest accuracy=0.875\n",
      "epoch=197\ttrain loss=0.044975\ttrain accuracy=1.000\ttest accuracy=0.938\n",
      "epoch=198\ttrain loss=0.037527\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=199\ttrain loss=0.037582\ttrain accuracy=1.000\ttest accuracy=1.000\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(200):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, (batch_image, batch_label) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        model=model.to(device)\n",
    "        batch_image, batch_label = batch_image.to(device), batch_label.to(device)\n",
    "        batch_output = model(batch_image)\n",
    "        batch_loss = loss_func(batch_output, batch_label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        _, train_predicted = torch.max(batch_output.data, 1)\n",
    "        train_acc += (train_predicted == batch_label).sum().item()\n",
    "\n",
    "    train_acc /= train_size\n",
    "    running_loss /= (step+1)\n",
    "\n",
    "    # ----------test----------\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for test_image, test_label in test_loader:\n",
    "        test_image, test_label = test_image.to(device), test_label.to(device)\n",
    "        test_output = model(test_image)\n",
    "        _, predicted = torch.max(test_output.data, 1)\n",
    "        test_acc += (predicted == test_label).sum().item()\n",
    "    test_acc /= test_size\n",
    "\n",
    "    print('epoch={:d}\\ttrain loss={:.6f}\\ttrain accuracy={:.3f}\\ttest accuracy={:.3f}'.format(\n",
    "        epoch, running_loss, train_acc, test_acc))\n",
    "\n",
    "    if test_acc >= best_accuracy:\n",
    "        save_path = './trained_models/'\n",
    "        if not os.path.exists(save_path):\n",
    "             os.makedirs(save_path)\n",
    "        torch.save(model.state_dict(), './trained_models/FCNN_model.pkl')\n",
    "        best_accuracy = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
